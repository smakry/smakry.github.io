---
layout: post
title: '缓存阅读笔记'
date: 2019-09-05
author: smakry
tags: 缓存 阅读笔记
---

> 更快的目标


### 揭开缓存面纱

狭义的缓存：指的是`CPU缓存`（CPU与内存之间的临时存储器，容量比内存小得多但是交互速率比内存快很多，CPU缓存`协调CPU高速运算与内存大容量`），先从CPU缓存中找，未找到再到相对慢的内存中读取，同时把数据块调入缓存中，后续不用再调用内存。（静态随机存取存储器（Static Random-Access Memory,SRAM）,静态只要通电数据就能恒常保持）  

![存储器层次结构](https://github.com/smakry/smakry.github.io/raw/master/imags/%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84.png)

广义的缓存：二者之间速率相差大的，`协调二者差异的结构`都可称缓存。  


Web应用架构一般有如下几层（不同层级之间都可以存在缓存）：  

![常用web架构](https://github.com/smakry/smakry.github.io/raw/master/imags/%E5%B8%B8%E7%94%A8web%E6%9E%B6%E6%9E%84.png)  

- 数据库加上缓存，减少文件系统I/O
- 应用程序加上缓存，减少对数据库的查询
- Web服务器加上缓存能够减少应用服务器请求  
- 客户端浏览器加上缓存能够减少对网站的访问  
- 计算机在CPU和主存之间添加高速缓存以加快读取速率  
- 操作系统磁盘中一般也添加缓存，减少磁盘机械操作  


缓存提升点：  
- 性能：避免数据的重复创建、处理和传输（无用功付出）  
- 稳定性：减少请求及资源浪费（减轻负担，出错的可能就减小）  
- 可用性：数据服务提供方意外停止，`一定时间`仍能正常提供支持（有备胎）

<http://www.sohu.com/a/272322730_505779>  

### 分布式缓存原理  

#### 本地缓存（进程内缓存，多应用程序无法直接共享）  

应用和cache`同在一个进程内部`（请求缓存快，没有过多网络开销），例如Ehcache、Guava Cache等。适合单应用，但同时缓存跟应用程序耦合（单个应用奔溃，数据丢失），集群各节点需要维护自己的单独缓存

#### 分布式缓存特性  

能够`高性能读取`数据、`动态扩展`缓存节点、`自动发现和切换故障`节点、`自动均衡数据分区`，为使用者提供图形化的管理界面，部署和维护方便。例如：Memcached、Redis、Tair等

#### 分布式缓存实现原理  

- **数据读取**：`一个`服务端实现管理和控制`多个数据存储节点`客户端，读取数据通过一致性hash（节点发生变化无需重新计算哈希值）找到数据存储的节点。（一致性hash <https://www.jianshu.com/p/e968c081f563>）  
- **数据均匀分布**：（节点少时可能堆积部分节点，可以把`节点细化，扩大基数`，保证分布均匀，如IP增加尾缀）
- **数据的热备份**：多台服务器计算IP地址`哈希值后根据大小排序组成环`，`顺时针`看环，数据存储到1台服务器后，这1台服务器负责把数据拷贝给顺时针下1台，以此类推（每个服务器有自身业务数据，也有上一节点的热备份数据）。

#### 影响缓存性能因素  

提高缓存收益，`尽量从缓存获取数据`，避免缓存数据失效。根据业务权衡通过缓存预加载（预热）、增加存储容量、调整缓存粒度、更新缓存来提高命中率。

- **序列化**：访问本地缓存，JVM语言而言可选择堆内（以对象形式存储，不用考虑序列化）和堆外（以`字节类型存储`，需考虑序列化和发序列化），序列化带来CPU消耗，那么序列化`一般是缓存对象解析的对象结构`  

- **命中率**：缓存的命中率高表示缓存的收益越高，应用性能好（`响应时间越短，吞吐量越高`），抗并发的能力越强，影响命中率因素：
    - 业务场景和业务需求：
        - `重复读`取较多的业务场景（写场景少的）
        - `时效性低`的（时效性要求高直接影响缓存的过期时间和更新策略）
        - 互联网应用的大多数业务场景都适合使用缓存  
    - 缓存的设计粒度和策略  
        - `粒度越小`命中率越高（粒度小当变化是影响的数据量小，数据的更新耗时低）  
        - 缓存的更新/过期策略  

- **缓存容量和基础设施**：  
`容量低的情况容易导致缓存失效和淘汰`（目前多数采用的LRU（least recently used，最近最少使用）算法）。应用`内置本地缓存容易出现单机瓶颈`，`分布式缓存容易扩展`，不同缓存和中间间效率和稳定性存在差异。  

- **缓存故障处理**：缓存故障降低失效影响，典型做法`一致性hash`或者`节点冗余`（容灾备份数据）

#### 缓存的更新和过期策略  

- 固定过期日期，被动失效
- 感知数据变更，主动更新
- 感知数据变更，主动更新；并设置过期时间被动失效（保底）  
- 按照数据的冷热性制定策略，`热数据（频繁访问）主动失效并reload`；`冷数据（离线不经常访问）只失效不reload`  

当数据发生变化，`直接更新缓存`的值会比移除缓存（或者让缓存过期）的命中率更高，系统复杂度也会更高。（数据先读取缓存的固命中率高，但会带来持久化问题）

#### 缓存淘汰策略  

- FIFO（first in first out）先进先出策略，比较数据时间
- LFU（less frequently used）最少使用策略，使用计数器记录条目被访问频率  
- LRU（least recently used）最近最少使用策略，常访问提到顶部，容量满从底部淘汰。“年龄位”精确条目访问时间及淘汰后其它条目的“年龄位”改变
- ARC（adjustable replacement cache，自适应缓存替换算法），同时跟踪LFU和LRU，以及驱逐缓存条目，获得可用缓存的最佳使用  
- MRU（most recently used，最近最常使用算法），最先移除最近最常用的条目（主要用于互斥数据访问的场景）

### 高并发常见缓存问题  

#### 1.缓存失效：
- 失效原因：
    - 大量key同一时间失效
    - 主被动场景同一时间加载一大批数据到缓存
- 失效场景：
    - 预定火车票
- 解决方案：
    - “同一时间”着手散列拆分失效时间

#### 2.缓存穿透
- 穿透原因：
    - 缓存中未命中数据，DB中也未命中数据。每次请求直接穿透到DB
- 穿透场景：
    - 请求不存在的此次信息
- 解决方案：
    - 不存在的key做对应的响应，写入到缓存中（量大耗费空间），设置较短失效时间
    - 布隆过滤器，筛选有效key（过滤器越来越庞大，需定期重置）

#### 3.缓存击穿（缓存失效的特例）
- 击穿原因：
    - 热点数据缓存key失效
- 击穿场景：
    - 热门新闻缓存失效，穿透到DB
- 解决方案：
    - 采用LRU(Least recently used，最近最少使用)队列将访问到的数据加队列头部，去掉队列尾部（访问的数据再次访问的概率更高，偶然访问的影响）
    - 多级LRU权重访问（访问增加访问的次数淘汰规则）

#### 4.缓存雪崩
- 雪崩原因：
    - 部分节点不支持rehash导致整个缓存系统不可用
    - 洪峰流量，部分节点过载宕机，扩散其它节点导致整个系统不可用
- 雪崩场景：
    - 大量缓存节点不可用，穿透DB，DB过载
    - 分布式设计采用一致性hash，洪峰集中访问几个节点导致过载
- 解决方案：
    - DB设置开关（达到阈值关闭，低于阈值恢复后打开）
    - 多机架多副本，单个未命中读取其它副本
    - 监控缓存系统，超出阈值执行自动故障转移

#### 5.数据不一致
- 不一致原因：
    - 缓存与DB，缓存副本之间存在不一致
- 不一致场景：
    - DB更新后，缓存所在机器异常导致更新失败
    - 一致性hash+rehash导致更新异常数据不一致
- 解决方案：
    - 更新淘汰失败，多次尝试，失败后将key写入消息队列，缓存正常后处理并删除key
    - 简短缓存时间，自动过期
    - 拒绝rehash策略

#### 6.数据并发竞争
- 并发经常原因：
    - 高并发同时请求缓存未存在数据，穿透DB，DB压力大争
- 并发竞争场景：
    - 车票车次信息，缓存信息过期大量用户同时请求
- 并发竞争解决方案：
    - 缓存多副本，单个未命中转移

#### 7.Hot key
- Hot key原因：
    - 冷数据(不常被访问的)、热数据（访问频率非常高）。新闻热点短时访问率高
- Hot key场景：
    - 热点新闻
    - 秒杀
    - 春运
- Hot key解决方案：
    - 热数据散列，存储不同节点
    - 监控扩容
    - 本地缓存，减少缓存服务器请求（本地可能多次访问）

#### 8.Big key
- 数据大副本少，请求多，加载慢，DB挂（后续继续研究）