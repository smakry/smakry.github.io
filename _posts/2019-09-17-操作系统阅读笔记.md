---
layout: post
title: '操作系统阅读笔记'
date: 2019-09-17
author: smakry
tags: 操作系统 阅读笔记
---

> **管理**计算机硬件与软件资源的计算机程序，计算机系统的内核与基石

https://www.cnblogs.com/xdyixia/p/9274909.html

### 并发与并行？

1. 并行：在同一时刻，有多条指令在`多个处理器上`**同时**执行，从微观还是从宏观看，都是一起执行。  
![并行](https://github.com/smakry/smakry.github.io/raw/master/imags/%E5%B9%B6%E8%A1%8C.png)  
2. 并发：在同一时刻`只能有一条指令`执行，但多个进程指令被快速的`轮换执行`，宏观上具有多个进程同时执行的效果，但微观上并不是同时执行，只是把时间分成若干段，使多个进程快速交替的执行。  
![并发](https://github.com/smakry/smakry.github.io/raw/master/imags/%E5%B9%B6%E5%8F%91.png)  

### 操作系统的四大特性

操作系统的四大特征：并发、共享、虚拟、异步  
1. 并发：在一段时间内，运行多个程序，执行多个任务，从宏观上来说，操作系统引入进程的目的就是为了使程序能并发执行。    
2. 共享：资源共享，系统中的资源可供多个`并发执行的进程`共同使用。由于资源的属性不同，多个进程对资源的共享方式也不同，可分为互斥共享方式和同时访问方式。  
- 互斥共享方式：一段时间内`只允许一个进程`访问该资源。  
- 同时共享方式：某些资源，一段时间内允许多个进程“同时”对它们进行访问，这个`“同时”是宏观上`的，在`微观上可能是分时共享`（eg：磁盘设备）。  
3. 虚拟：虚拟性是`一种管理技术`，把物理上的一个实体变成逻辑上的多个对应物，或把物理上的多个实体变成逻辑上的一个对应物的技术。采用虚拟技术的目的是为用户提供易于使用、方便高效的操作环境。虚，理解为用户感觉上的。   
4. 异步：在多道程序环境下，允许多个程序并发执行。但由于`资源有限`，进程的执行`不是一贯到底，而是走走停停`，已不可预知的速度向前推进。  
异步性使得操作系统运行在随机的环境下，`可能导致进程产生与时间相关的错误，但只要运行的环境相同，操作提供必须保证多次运行进程，都获得相同的结果`。  

### 进程与线程

#### 进程  

1. 多进程的组织形式：
    - PCB（Process Control Block，进程控制块）：`用来记录进程信息的数据结构`（管理进程的核心，包含了PID等进程的所有关键信息）
2. 进程的状态：就绪状态、执行状态、阻塞状态（多线程时也是这些状态）  
![进程状态](https://github.com/smakry/smakry.github.io/raw/master/imags/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81.png)  
    - 就绪->执行：处于就绪状态的进程，在调度程序为之分配了处理机之后便开始执行。  
    - 执行->就绪：正在执行的进程如果因为分配他的`时间片已经用完`，而被`剥夺处理机`。  
    - 执行->阻塞：如果因为某些原因致使当前的进程执行受阻，使之不能执行。  

3. 队列：就绪队列、等待（阻塞）队列

##### CPU调度算法（在就绪队列中怎么**挑选进程**让CPU执行）  

- 周转时间：从开始申请执行任务，到执行`任务完成`。  
- 响应时间：从开始申请执行任务，到`开始执行`任务。 

决策模式说明选择函数在执行的数据的处理方式（一个调度算法是否能抢占，对进程的顺序有着极大的影响）：  

- 非抢占：一旦进入运行状态，就不会终止直到运行结束。
- 抢占式：当前正在运行的进程可以被打断，并转移到就绪态。 

1. FCFS（First Come First Service，先来先服务），非抢占式，根据进程到达时间决定先后。
2. SJF（Short Job First，最短进程优先）/又称SPN，非抢占式，根据`到达时间选择短作业`（即短作业在长作业运行期间到达也是长作业先执行）
3. SRT(Shortest Remaining Time,最短剩余时间优先)，抢占式，作业过程新进作业执行时间较短，`中断当前作业`（当前进入就绪，后续继续执行），新作业提上来优先执行。可以认为是优先级调度中的一种。
4. RR（Time Slicling，SL，时间片轮转）/又称轮转RR，抢占式，按到达的先后讲进程放入队列中，给队首进程分配CPU时间片，时间片用完之后计时器发出中断，暂停当前进程将其放入队尾，循环。
5. HRRN（Highest Response Ratio Next，高响应比优先调度），非抢占式，优先级调度中的一种。  
响应比 = （等待时间 + 服务时间）/ 服务时间  
6. 多级反馈队列调度算法：目前公认较好的调度算法，设置多个就绪队列并为每个队列设置不同的优先级，第一个队列的优先级最高，其余依次递减。优先级高的队列分配的时间片越短，进程到达之后按FCFS放入第一个队列，如果调度执行后没有完成，那么放到第2个`队列尾部`等待调度，如果第二次调度仍然没有完成，放入第3个队列尾部...。`只有当前队列为空的时候才会去调度下一个`队列的进程。  

#### 线程  

线程有自己的TCB（Thread Control Block，线程控制块），只负责这条流程的信息，包括PC程序计数器，SP栈，State状态，寄存器和线程ID。线程有`内核线程`和`用户级线程`，一般我们说的都是用户级线程，内核级线程由内核管理。  

- `只有内核级线程才能发挥多核性能`，因为内核级线程`共用一套MMU`（即内存映射表），统一分配核1核2（即有多个CPU，可以一个CPU执行一个内核级线程）。`进程无法发挥多核性能`，因为进程切换都得切MMU。
- 为什么需要内核级线程？如果只有用户级线程，在内核中只能看到进程，所以当用户级线程中一个线程进行IO读写阻塞时，内核会将该线程所在的进程直接切换。例如当用浏览器打开网页，这个进程中有下载数据线程，有显示数据线程，当数据下载读写阻塞时，内核直接切到qq（这些切换是指在CPU上运行的程序的切换）。  

#### 进程与线程的对比？

进程 是`系统进行资源调度和分配`的基本单位；  
线程 是`CPU调度`的基本单位。  

进程 = 资源（包括寄存器值，PCB，内存映射表MMU）+ TCB（栈结构）  
线程 = TCB（栈结构）  
  
线程 的`资源是共享`的  
进程 间的`资源是分隔独立`的，内存映射表不同，占用物理内存地址是分隔的  
  
线程 的切换只是切换PC，切换了TCB（栈结构）  
进程 的切换不仅要切换PC，还包括切换资源，即切换内存映射表  

#### 进程间通信和线程同步

IPC（Inter-Process Communication，进程间通信）主要是指多个`进程间的数据交互`。  
线程间同步（Thread Synchronization）主要是指维护多个`线程`之间`数据准确、一致性`。  

<https://mp.weixin.qq.com/s/VV_mTpuOYFIZRb94mwhr2Q>  

##### 进程间通信  

进程间七大通信方式：  
pipe、file、msg、shm、sem、signal、socket  

1. Pipe（管道）：管道是一种半双工的通信方式，数据只能单向流动，通过管道从一个进程流向另一个进程是具有时间先后顺序的。管道文件是一种临时文件，不是磁盘上的真真正正的文件，`是一块内存区域`。  
`无名管道`只能在具有亲缘关系的进程间使用（通常指父子进程关系）。
`有名管道`（named pipe）非父子进程间通信。  
2. file（文件）：每打开一个文件，就会产生一个文件控制块，而文件控制块与文件描述符是一一对应的，通过对文件描述符的操作进而对文件进行操作（可以是不相关进程间的通信）。
3. msg（Message Queue，消息队列）：消息队列是由消息的链表，`存放在内核中`并由`消息队列标识符标识`。消息队列克服了传递信息少、管道只能承载无格式字节流以及缓冲区大小受限制等缺点。
4. shm（Shared Memory，共享内存）：共享内存就是`映射一段能被其他进程所访问的内存`，这段共享内存由一个进程创建，但多个进程都可以访问。`共享内存是最快的IPC方式`，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。
5. sem（Semaphore，信号量）：`信号量是一个计数器`，可以用来控制多个进程对共享资源的访问。它`常作为一种锁机制`，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
6. signal/sinal（信号）:用于通知接收进程某个事件已经发生需要处理。  
- 信号通信的目的:`某某事件发生，此时需要处理什么`。
- 进程间（可以是不相关的进程）传递信号场景：`信号又被称之为中断`，需要处理什么（对应的是中断处理函数），此时设置断点，形参入栈，`保存现场信息`，然后去执行中断处理函数，当处理完成之后，恢复现场信息，程序继续往下执行。  
7. socket（套接字）:`网络之间`不同进程间（可以不同机器）通信，属于网络编程部分。  

##### 线程间同步  

`线程间通信的主要目的是用于线程同步`，所以没有像进程通信中的用于数据交换的通信机制。线程间同步主要有以下方式：  
mutex（互斥量）、rwlock（读写锁）、cond（条件变量）、semaphore（信号量）、spinlock（自旋锁）  

<https://blog.csdn.net/majianfei1023/article/details/51550322>

1. mutex（互斥量）：互斥量`本质上说是一把锁`，在访问共享资源前对互斥量进行加锁，在访问完成后释放互斥量。对互斥量进行加锁以后，其他视图再次对互斥量加锁的线程都会被阻塞直到当前线程释放该互斥锁。如果释放互斥量时有一个以上的线程阻塞，那么所有该锁上的阻塞线程都会变成可运行状态，第一个变成运行状态的线程可以对互斥量加锁，其他线程就会看到互斥量依然是锁着，只能再次阻塞等待它重新变成可用，这样，`一次只有一个线程可以向前执行`。  
2. rwlock（读写锁）：读写锁与互斥量类似，不过`读写锁拥有更高的并行性`。互斥量要么是锁住状态，要么是不加锁状态，而且一次只有一个线程可以对其加锁。读写锁有3种状态：读模式下加锁状态，写模式下加锁状态，不加锁状态。一次只有一个线程可以占有写模式的读写锁，但是`多个线程可以同时占有**读模式**`的读写锁。  
当读写锁是写加锁状态时，在这个锁被解锁之前，所有视图对这个锁加锁的线程都会被阻塞。当读写锁在读加锁状态时，所有试图以读模式对它进行加锁的线程都可以得到访问权，但是任何希望以写模式对此锁进行加锁的线程都会阻塞，直到所有的线程释放它们的读锁为止。  
3. cond（条件变量）：条件变量是线程可用的另一种同步机制。`互斥量用于上锁，条件变量则用于等待`，并且条件变量总是需要与互斥量一起使用，运行线程以无竞争的方式等待特定的条件发生。  
条件变量本身是由互斥量保护的，线程在改变条件变量之前必须首先锁住互斥量。其他线程在获得互斥量之前不会察觉到这种变化，因为互斥量必须在锁定之后才能计算条件。  
4. semaphore（信号量）：它允许多个线程在同一时刻访问同一资源，但是需要限制在`同一时刻访问此资源的最大线程数目`。信号量对象对线程的同步方式与前面几种方法不同，信号量允许多个线程同时使用共享资源，这与操作系统中的PV操作相同。它指出了同时访问共享资源的线程最大数目。
5. spinlock（自旋锁）:自旋锁与互斥量类似，但它不是通过休眠使进程阻塞，而是`在获取锁之前一直处于忙等（自旋）阻塞状态`。自旋锁可以用于以下情况：锁被持有的时间短，而且线程并不希望在重新调度上花费太多的成本。  

##### 死锁

在两个或多个`并发进程`中，如果每个进程持有某种资源而又都等待别的进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁。通俗地讲，就是两个或多个进程被无限期地阻塞、`相互等待`的一种状态。

1. 死锁产生条件：  
    - 互斥条件：一个资源一次`只能被一个进程使用`。
    - 请求保持条件：一个进程因请求资源而阻塞时，对`已经获得的资源保持不放`。  
    - 不可抢占条件：进程已获得的资源在未使用完之前`不能强行剥夺`。  
    - 循环等待条件：如果进程之间形成一种头尾相接的`循环等待`资源的关系。  
2. 死锁处理：
    - 预防死锁：`破坏产生死锁的4个必要条件`中的一个或者多个，实现起来较简单，但如果限制过于严格会降低系统资源的利用率以及吞吐量。
    - 避免死锁：在资源的动态分配中，`防止系统进入不安全状态`（可能产生死锁的状态）
    - 检测死锁：允许系统运行过程中产生死锁，在死锁发生后，采用一定的算法进行检测，并确定与死锁相关的资源和进程，并清除检测到的死锁（检测并清除的方法实现难度高）。
    - 解除死锁：与死锁检测配合，将系统从死锁中解脱出来（撤销进程或者剥夺资源）。对检测到的和死锁相关的进程以及资源，通过撤销或者挂起的方式，释放一些资源并将其分配给处于阻塞状态的进程，使其转变为就绪态。  

### 内存管理

<https://www.jianshu.com/p/ca94dcc014c7>
  内存管理演变过程																	|
  纯粹分段	|一个程序就是一段，使用基址极限来管理（固定加载地址、固定分区、非固定分区、交换）	|  
  分页		|一个程序分为多个固定大小的页面，使用页表来进行管理							|  
  逻辑分段	|程序逻辑分为多段，用一基址极限对来管理，基址极限存放在段表里					|  
  段页式		|程序按逻辑分为多段，每一段内又进行分页，使用段页表来管理						|  

#### 物理内存（取决于CPU寻址空间和实际内存条大小）  

- 寻址空间0-2^32（32位机器），那么对应的是4GB（4 * 1024 * 1024 * 1024 = 2^32）  
- 物理内存`分配内存是随机的`,程序运行时候地址不确定（程序要访问0x00000000，但分配随机所以0x00000000不一定是程序所要访问的地址）
- 直接使用物理内存（进程空间不隔离，没有权限保护，进程间相互影响）
- 直接使用物理内存（程序需要连续的内存地址下），碎片产生多（小内存块释放不能再次被需大内存程序使用），内存利用率低

#### 虚拟地址空间  

解决直接操作物理内存带来的问题，引入虚拟空间（可以无限大），`每个进程有自己的虚拟空间`（地址可以从“0”开始，解决地址不确定）。  

#### 基本内存管理（分段）  

在虚拟地址空间和物理地址空间做一一映射（程序操作的是虚拟地址空间），映射的是一片`连续的`物理内存。物理内存做分段处理，用于映射。  
- 虚拟地址空间解决地址不确定问题
- 物理内存分段解决了内存重叠问题，空间上隔离
- 分段同样是一片连续的物理内存，内存利用率低的问题没有解决

1.固定分区  
![固定分区1](https://github.com/smakry/smakry.github.io/raw/master/imags/%E5%9B%BA%E5%AE%9A%E5%88%86%E5%8C%BA1.png)  

![固定分区2](https://github.com/smakry/smakry.github.io/raw/master/imags/%E5%9B%BA%E5%AE%9A%E5%88%86%E5%8C%BA2.png)

2.非固定分区  
除系统占用的内存空间外，`其余作为一个整体`，每个程序进来计算所需内存空间分配（但存在运行时候所需内存空间的增加导致无法运行或者发生分区交换，预留太多浪费利用率低）  

![非固定分区](https://github.com/smakry/smakry.github.io/raw/master/imags/%E9%9D%9E%E5%9B%BA%E5%AE%9A%E5%88%86%E5%8C%BA.png)

3.交换分区  
当运行时分区不足以供程序使用，讲当前程序`倒到外置存储`，然后重新分配更大空间内存，再`重新`加载程序

4.双基址（2个相同的程序，共享指令（可理解程序代码段），但分配不同的数据段）  

#### 内存分页  

解决分段带来的内存利用率低的问题，引入分页技术。将`虚拟内存空间和物理内存空间`**皆划分**为大小相同的页面，如4KB、8KB或16KB等，并以页面作为内存空间的最小分配单位，一个程序的一个页面可以存放在任意一个物理页面里。  
通过`页表`（一个硬件数据结构）查找管理页面。

分页解析详见：<https://blog.csdn.net/iostream1001001/article/details/77124459>  

- （优点）分页的大小比较小，不会产生外部碎片
- （优点）一个进程占用的内存空间`可以不是连续`的，并且一个进程的虚拟页面在不需要的时候`可以放在磁盘中`  
- （缺点）页表大小很大  
32位寻址4k大小的页的页表大小为2^20(页数)*4Byte（表项长度=20位页号+12位控制位）=4MB  
- （缺点）分页系统存在的一个无法容忍，同时也是分页系统无法解决的一个缺点就是：`一个进程只能占有一个虚拟地址空间`。在此种限制下，一个程序的大小至多只能和虚拟空间一样大，其所有内容都必须从这个共同的虚拟空间内分配。

#### 页面置换算法  

**缺页中断**：在分页系统中，一个虚拟页面既有可能在物理内存，`也有可能保存在磁盘中`。CPU调用的虚拟页面地址对应的物理内存不存在（在磁盘中），此时将产生缺页中断（`中断处理`：将虚拟页面对应的内存地址找到并加载到内存）。  
如果发生缺页中断，就需要从磁盘上将需要的页面调入内存。如果`内存没有多余的空间`，就需要在现有的页面中选择一个页面进行替换。使用不同的置换算法，页面更换的顺序也会各不相同。如果挑选的页面是之后很快又要被访问的页面，那么系统将很快再次出现缺页中断，这样磁盘读写的效率远远低于内存的访问速度，缺页中断的代价就非常高。  
页面置换算法就是降低置换频率或次数。  

- 随机更换算法：随机选择一个进行置换（随机性）
- FIFO（First In First Out，先进先出）:更换最早进入内存的页面
- 第二次机会算法：在FIFO（先进先出）的基础上多给予1次机会再做置换（选择都是从头开始，头被命中的概率大）  
- 时钟算法：优化第二次机会算法（类似`时钟的分布`，当前指针指向的位置开始选择，无需重头开始）
- 最优更换算法（理想的算法，实际上不存在）：就是选择没有最久最少使用到的页面置换
- NRU(Not Recently Used,最近未使用)算法：选择一个最近一段时间未被访问的页面置换(可能下一时刻就被用到了)
- LRU（Least Recently Used，最近最少使用）：在NRU基础上，不仅考虑最近没使用，而且考虑最近最少使用
- 工作集算法：对访问的页面做`集合划分（访问次数）`，程序访问的（工作集），置换从头查找置换
- 工作集时钟算法：在工作集基础上，查找置换采用时钟分布，指针指向的位置开始查找

#### 逻辑分段、重叠（overlay）  

逻辑分段程序按照逻辑关系分成不同的段（看做多个进程a、b、c...），当原始程序需要的内存空间超过了物理内存大小，逻辑分段执行（a做完释放内存，b继续做,b做完释放内存，c继续...）这就是重叠.
